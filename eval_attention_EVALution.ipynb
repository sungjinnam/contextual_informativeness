{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # EVALution 1.0\n",
    "# Dataset containing Semantic Relations and Metadata, for Training and Evaluating Distributional Semantic Models\n",
    "# The resource is freely available. If you use it, please cite the description paper:\n",
    "# - Enrico Santus, Frances Yung, Alessandro Lenci, and Chu-Ren Huang. 2015. EVALution 1.0: An Evolving Semantic Dataset for Training and Evaluation of Distributional Semantic Models. Proceedings of the 4th Workshop on Linked Data in Linguistics, Beijing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# keras modules\n",
    "import tensorflow as tf\n",
    "# from keras.models import load_model\n",
    "\n",
    "from keras.preprocessing.text import text_to_word_sequence, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# from keras.utils import plot_model\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.models import save_model, load_model\n",
    "# from tensorflow.keras.utils import plot_model\n",
    "# import keras_tqdm\n",
    "# from livelossplot.keras import PlotLossesCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom layers from external files\n",
    "from layers.embeddings import ElmoLayer\n",
    "from layers.attention import AttentionLayer\n",
    "from models.build_models import build_model_elmo, initialize_vars\n",
    "from models.train_models import *\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some option settings for Jupyter notebook and TF\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collum descriptions::\n",
    "#  - first relatum: it is one of the relata in the file RELATA.txt\n",
    "#  - relation: it can be one of the following relations: Antonym, Synonym, IsA (hypernymy), PartOf (meronymy), MemberOf (meronymy), MadeOf (meronymy), Entailment, HasA (possession), HasProperty (attribute). For the definition of these relations, please refer to: https://github.com/commonsense/conceptnet5/wiki/Relations.\n",
    "#  - second relatum: it is one of the relata in the file RELATA.txt\n",
    "#  - tags: this field contains a comma separated list of tags, with their frequency among the total number of annotators (e.g. \"CULTURE_1/5,EVENT_4/5\" stays for CULTURE was tagged by 1 subject on 5, while PLANT by 4 on 5). NOTE: The reliability of the tags is slow, as some subjects have tried to cheat; we suggest you to rely on tags that were judged at least twice.\n",
    "#  - sentence: this field contains a sentence that paraphrases the relation; this sentence was used in the crowdsourcing task to assess the quality of the relation.\n",
    "#  - distribution of votes: the next five columns are integers that represent the number of votes for each value, with reference to the sentence in the previous field: \"strong disagreement\" (the first one, value=1), \"disagreement\", \"neutral\", \"agreement\" and \"strong agreement\" (the last one, value=5).\n",
    "#  - agreement between subjects as reported by Crowdflower.\n",
    "#  - number of subjects who voted the agreement with the sentence.\n",
    "#  - average score (in the range between 1=\"strongly disagree\" and 5=\"strongly agree\").\n",
    "#  - variance among the votes.\n",
    "#  - average score minus the variance.\n",
    "#  - source from which the pair was extracted.\n",
    "#  - score in the source, if available.\n",
    "eval_colnames = [\n",
    "    \"relata1\",\n",
    "    \"relation\",\n",
    "    \"relata2\",\n",
    "    \"tags\",\n",
    "    \"sentence\",\n",
    "    \"votes_sc_1\",\n",
    "    \"votes_sc_2\",\n",
    "    \"votes_sc_3\",\n",
    "    \"votes_sc_4\",\n",
    "    \"votes_sc_5\",\n",
    "    \"votes_agreement\",\n",
    "    \"votes_no_agree\",\n",
    "    \"votes_avg_score\",\n",
    "    \"votes_var_score\",\n",
    "    \"votes_avg_var_diff\",\n",
    "    \"pair_source_name\",\n",
    "    \"pair_source_score\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sjnam/anaconda3/envs/infmtv_keras_gpu/lib/python3.6/site-packages/ipykernel_launcher.py:1: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "df_eval = pd.read_table(\"dataset/EVALution_1.0/RELATIONS.txt\", sep=\"\\t\", header=None, names=eval_colnames, index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['sentence'] = df_eval['sentence'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relata1</th>\n",
       "      <th>relation</th>\n",
       "      <th>relata2</th>\n",
       "      <th>tags</th>\n",
       "      <th>sentence</th>\n",
       "      <th>votes_sc_1</th>\n",
       "      <th>votes_sc_2</th>\n",
       "      <th>votes_sc_3</th>\n",
       "      <th>votes_sc_4</th>\n",
       "      <th>votes_sc_5</th>\n",
       "      <th>votes_agreement</th>\n",
       "      <th>votes_no_agree</th>\n",
       "      <th>votes_avg_score</th>\n",
       "      <th>votes_var_score</th>\n",
       "      <th>votes_avg_var_diff</th>\n",
       "      <th>pair_source_name</th>\n",
       "      <th>pair_source_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abstract</td>\n",
       "      <td>Antonym</td>\n",
       "      <td>concrete</td>\n",
       "      <td>OBJECT_3/5,EMOTION_2/5,EVENT_2/5,RELATIONSHIP_1/5</td>\n",
       "      <td>abstract can be used as the opposite of concrete</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.912340</td>\n",
       "      <td>5</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>wordnet/4.0</td>\n",
       "      <td>score</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>accident</td>\n",
       "      <td>Antonym</td>\n",
       "      <td>plan</td>\n",
       "      <td>CULTURE_1/5,EVENT_4/5</td>\n",
       "      <td>accident can be used as the opposite of plan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>26</td>\n",
       "      <td>0.953509</td>\n",
       "      <td>38</td>\n",
       "      <td>4.684211</td>\n",
       "      <td>0.221906</td>\n",
       "      <td>4.462304</td>\n",
       "      <td>verbosity</td>\n",
       "      <td>0.0445190226130131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accident</td>\n",
       "      <td>Antonym</td>\n",
       "      <td>purpose</td>\n",
       "      <td>EVENT_5/5</td>\n",
       "      <td>accident can be used as the opposite of purpose</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.913917</td>\n",
       "      <td>5</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.100000</td>\n",
       "      <td>verbosity</td>\n",
       "      <td>0.13952094877868304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accident</td>\n",
       "      <td>Synonym</td>\n",
       "      <td>event</td>\n",
       "      <td>EVENT_5/5</td>\n",
       "      <td>accident can be used with the same meaning of event</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.935375</td>\n",
       "      <td>5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>wiktionary/de/en</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>accident</td>\n",
       "      <td>IsA</td>\n",
       "      <td>error</td>\n",
       "      <td>EVENT_4/5,RELATIONSHIP_1/5</td>\n",
       "      <td>accident is a kind of error</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.911600</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>conceptnet/4/en</td>\n",
       "      <td>1.5849625007211563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>accident</td>\n",
       "      <td>IsA</td>\n",
       "      <td>happen</td>\n",
       "      <td>EVENT_5/5</td>\n",
       "      <td>accident is a kind of happen</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.965458</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>wordnet/3.0</td>\n",
       "      <td>1.5849625007211563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>accident</td>\n",
       "      <td>IsA</td>\n",
       "      <td>mistake</td>\n",
       "      <td>RELATIONSHIP_1/60,NATURE_1/60,FOOD_1/60,COMMUNICATION_2/60,OBJECT_3/60,CULTURE_2/60,EVENT_57/60</td>\n",
       "      <td>accident is a kind of mistake</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.954483</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>conceptnet/4/en</td>\n",
       "      <td>1.5849625007211563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>account</td>\n",
       "      <td>Synonym</td>\n",
       "      <td>record</td>\n",
       "      <td>OBJECT_2/5,CULTURE_1/5,EVENT_2/5,BUSINESS_2/5</td>\n",
       "      <td>account can be used with the same meaning of record</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.908725</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>wiktionary/de/en</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>account</td>\n",
       "      <td>Synonym</td>\n",
       "      <td>report</td>\n",
       "      <td>EVENT_3/5,BUSINESS_2/5,NATURE_1/5</td>\n",
       "      <td>account can be used with the same meaning of report</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.967600</td>\n",
       "      <td>5</td>\n",
       "      <td>4.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>4.300000</td>\n",
       "      <td>wiktionary/de/en</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>account</td>\n",
       "      <td>Synonym</td>\n",
       "      <td>score</td>\n",
       "      <td>OBJECT_2/6,EVENT_6/6,BUSINESS_1/6,NATURE_1/6</td>\n",
       "      <td>account can be used with the same meaning of score</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.962425</td>\n",
       "      <td>5</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>wiktionary/de/en</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    relata1 relation   relata2  \\\n",
       "0  abstract  Antonym  concrete   \n",
       "1  accident  Antonym  plan       \n",
       "2  accident  Antonym  purpose    \n",
       "3  accident  Synonym  event      \n",
       "4  accident  IsA      error      \n",
       "5  accident  IsA      happen     \n",
       "6  accident  IsA      mistake    \n",
       "7  account   Synonym  record     \n",
       "8  account   Synonym  report     \n",
       "9  account   Synonym  score      \n",
       "\n",
       "                                                                                              tags  \\\n",
       "0  OBJECT_3/5,EMOTION_2/5,EVENT_2/5,RELATIONSHIP_1/5                                                 \n",
       "1  CULTURE_1/5,EVENT_4/5                                                                             \n",
       "2  EVENT_5/5                                                                                         \n",
       "3  EVENT_5/5                                                                                         \n",
       "4  EVENT_4/5,RELATIONSHIP_1/5                                                                        \n",
       "5  EVENT_5/5                                                                                         \n",
       "6  RELATIONSHIP_1/60,NATURE_1/60,FOOD_1/60,COMMUNICATION_2/60,OBJECT_3/60,CULTURE_2/60,EVENT_57/60   \n",
       "7  OBJECT_2/5,CULTURE_1/5,EVENT_2/5,BUSINESS_2/5                                                     \n",
       "8  EVENT_3/5,BUSINESS_2/5,NATURE_1/5                                                                 \n",
       "9  OBJECT_2/6,EVENT_6/6,BUSINESS_1/6,NATURE_1/6                                                      \n",
       "\n",
       "                                              sentence  votes_sc_1  \\\n",
       "0  abstract can be used as the opposite of concrete     0            \n",
       "1  accident can be used as the opposite of plan         0            \n",
       "2  accident can be used as the opposite of purpose      0            \n",
       "3  accident can be used with the same meaning of event  0            \n",
       "4  accident is a kind of error                          0            \n",
       "5  accident is a kind of happen                         0            \n",
       "6  accident is a kind of mistake                        0            \n",
       "7  account can be used with the same meaning of record  0            \n",
       "8  account can be used with the same meaning of report  0            \n",
       "9  account can be used with the same meaning of score   0            \n",
       "\n",
       "   votes_sc_2  votes_sc_3  votes_sc_4  votes_sc_5  votes_agreement  \\\n",
       "0  0           0           3           2           0.912340          \n",
       "1  0           0           12          26          0.953509          \n",
       "2  0           0           3           2           0.913917          \n",
       "3  0           1           3           1           0.935375          \n",
       "4  0           0           2           3           0.911600          \n",
       "5  0           0           2           3           0.965458          \n",
       "6  0           0           2           3           0.954483          \n",
       "7  0           0           2           3           0.908725          \n",
       "8  0           0           2           3           0.967600          \n",
       "9  1           0           2           2           0.962425          \n",
       "\n",
       "   votes_no_agree  votes_avg_score  votes_var_score  votes_avg_var_diff  \\\n",
       "0  5               4.400000         0.300000         4.100000             \n",
       "1  38              4.684211         0.221906         4.462304             \n",
       "2  5               4.400000         0.300000         4.100000             \n",
       "3  5               4.000000         0.500000         3.500000             \n",
       "4  5               4.600000         0.300000         4.300000             \n",
       "5  5               4.600000         0.300000         4.300000             \n",
       "6  5               4.600000         0.300000         4.300000             \n",
       "7  5               4.600000         0.300000         4.300000             \n",
       "8  5               4.600000         0.300000         4.300000             \n",
       "9  5               4.000000         1.500000         2.500000             \n",
       "\n",
       "   pair_source_name    pair_source_score  \n",
       "0  wordnet/4.0       score                \n",
       "1  verbosity         0.0445190226130131   \n",
       "2  verbosity         0.13952094877868304  \n",
       "3  wiktionary/de/en  1.0                  \n",
       "4  conceptnet/4/en   1.5849625007211563   \n",
       "5  wordnet/3.0       1.5849625007211563   \n",
       "6  conceptnet/4/en   1.5849625007211563   \n",
       "7  wiktionary/de/en  1.0                  \n",
       "8  wiktionary/de/en  1.0                  \n",
       "9  wiktionary/de/en  1.0                  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7492, 29)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsA            1880\n",
       "Antonym        1600\n",
       "HasProperty    1297\n",
       "Synonym        1086\n",
       "PartOf         654 \n",
       "HasA           544 \n",
       "MadeOf         317 \n",
       "Entails        82  \n",
       "MemberOf       32  \n",
       "Name: relation, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eval['relation'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# maximum sentence length\n",
    "max([len(sent.split()) for sent in df_eval['sentence']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## target word and sentence inputs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1 = [\"this\", 'is', 'a', 'test', 'sentence']\n",
    "tt2 = ['is', 'a']\n",
    "tt_ret = []\n",
    "for x in tt2:\n",
    "    for i, k in enumerate(tt1):\n",
    "        if(x==k):\n",
    "            tt_ret.append(i)\n",
    "tt_ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test', 'this']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.lower() for x in \"test_this\".split(\"_\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQ_LEN = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_notarg = proc_sentences_EVALution(df_eval, 'sentence', 'relata1', 'relata2', 'relation', \n",
    "                                            False, MAX_SEQ_LEN, RELATIONAL_CUE_TOKENS)\n",
    "sentences_wttarg = proc_sentences_EVALution(df_eval, 'sentence', 'relata1', 'relata2', 'relation', \n",
    "                                            True, MAX_SEQ_LEN, RELATIONAL_CUE_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([9, 9, 9, ..., 7, 9, 6]),\n",
       " array([['<UNK>', 'can', 'be', ..., '', '', ''],\n",
       "        ['<UNK>', 'can', 'be', ..., '', '', ''],\n",
       "        ['<UNK>', 'can', 'be', ..., '', '', ''],\n",
       "        ...,\n",
       "        ['<UNK>', 'can', 'have', ..., '', '', ''],\n",
       "        ['<UNK>', 'can', 'be', ..., '', '', ''],\n",
       "        ['<UNK>', 'is', 'a', ..., '', '', '']], dtype=object),\n",
       " array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_notarg\n",
    "# [sent[:10] for sent in sentences_notarg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[10, array(['<UNK>', 'can', 'be', 'used', 'with', 'the', 'same', 'meaning',\n",
       "        'of', 'record', '', '', '', '', '', '', '', '', '', '', '', '', '',\n",
       "        '', '', '', '', '', '', ''], dtype=object), array([0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]), array([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]), array([0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[sent[7] for sent in sentences_notarg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences_bert = proc_sentences_dscovar(df_eval, 'sentence', 'relata1', 'bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array(['abstract', 'accident', 'accident', ..., 'you', 'young', 'zero'],\n",
       "       dtype='<U18'),\n",
       " array(['abstract can be used as the opposite of concrete',\n",
       "        'accident can be used as the opposite of plan',\n",
       "        'accident can be used as the opposite of purpose', ...,\n",
       "        'you can have or can contain feel',\n",
       "        'young can be used as the opposite of mature',\n",
       "        'zero is a kind of number'], dtype='<U64')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bc78a30625a4a89b1b247883d30f6cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Converting examples to features', max=7492, style=ProgressSty…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 103, 1169, 1129, ...,    0,    0,    0],\n",
       "        [ 103, 1169, 1129, ...,    0,    0,    0],\n",
       "        [ 103, 1169, 1129, ...,    0,    0,    0],\n",
       "        ...,\n",
       "        [ 103, 1169, 1138, ...,    0,    0,    0],\n",
       "        [ 103, 1169, 1129, ...,    0,    0,    0],\n",
       "        [ 103, 1110,  170, ...,    0,    0,    0]]),\n",
       " array([[0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0],\n",
       "        [0, 1, 1, ..., 0, 0, 0]]),\n",
       " array([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0],\n",
       "        [1, 0, 0, ..., 0, 0, 0]]),\n",
       " array([[4.4       ],\n",
       "        [4.68421053],\n",
       "        [4.4       ],\n",
       "        ...,\n",
       "        [4.2       ],\n",
       "        [4.8       ],\n",
       "        [5.        ]]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = create_tokenizer_from_hub_module()\n",
    "sentences_bert_examples = convert_text_to_examples(sentences_bert[0], sentences_bert[1], df_eval['votes_avg_score'])\n",
    "sentences_bert_input = convert_examples_to_features(tokenizer, sentences_bert_examples, False, MAX_SEQ_LEN)\n",
    "sentences_bert_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention results scoring strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- processing the input\n",
    "    - consider relata1 as the target word\n",
    "    - sentence as a context\n",
    "    - see if the model pays more attention to relata2\n",
    "    - vice versa: this can control the target word location (beginning (relata1) or end (relata2) of the context sentence)\n",
    "- scoring\n",
    "    - (assuming relata1 is the target word)\n",
    "    - criterion 1: does the model pays more attention to relata2?\n",
    "    - criterion 2: does the model pays more attention to relational cues? \n",
    "        - e.g., abstract can be used as the *opposite* of concrete\n",
    "    - sum the rankings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method ElmoLayer.call of <layers.embeddings.ElmoLayer object at 0x7f0516266978>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ElmoLayer.call of <layers.embeddings.ElmoLayer object at 0x7f0516266978>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "1024\n",
      "WARNING: Entity <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f051521cf60>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f051521cf60>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method ElmoLayer.call of <layers.embeddings.ElmoLayer object at 0x7f06100c03c8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ElmoLayer.call of <layers.embeddings.ElmoLayer object at 0x7f06100c03c8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "1024\n",
      "WARNING: Entity <bound method ElmoLayer.call of <layers.embeddings.ElmoLayer object at 0x7f05a423dcc0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method ElmoLayer.call of <layers.embeddings.ElmoLayer object at 0x7f05a423dcc0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "1024\n",
      "WARNING: Entity <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f0516e625c0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f0516e625c0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method BertLayer.call of <layers.embeddings.BertLayer object at 0x7f0514279d30>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <layers.embeddings.BertLayer object at 0x7f0514279d30>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f050523d400>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f050523d400>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method BertLayer.call of <layers.embeddings.BertLayer object at 0x7f0277c65fd0>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <layers.embeddings.BertLayer object at 0x7f0277c65fd0>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method BertLayer.call of <layers.embeddings.BertLayer object at 0x7f0277c62cf8>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method BertLayer.call of <layers.embeddings.BertLayer object at 0x7f0277c62cf8>>: AttributeError: module 'gast' has no attribute 'Num'\n",
      "WARNING: Entity <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f026ded1b70>> could not be transformed and will be executed as-is. Please report this to the AutgoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: converting <bound method AttentionLayer.call of <layers.attention.AttentionLayer object at 0x7f026ded1b70>>: AttributeError: module 'gast' has no attribute 'Num'\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "sess = tf.Session()\n",
    "\n",
    "# model_elmo_notune_wtattn = build_model_elmo(MAX_SEQ_LEN, False, True,  False)\n",
    "# model_elmo_notune_noattn = build_model_elmo(MAX_SEQ_LEN, False, False, False)\n",
    "model_elmo_fntune_wtattn_1emb = build_model_elmo(MAX_SEQ_LEN, True, True,  False)\n",
    "model_elmo_fntune_wtattn_2emb = build_model_elmo(MAX_SEQ_LEN, True, True, True)\n",
    "model_bert_fntune_wtattn_1emb = build_model_bert(MAX_SEQ_LEN, True, True,  False)\n",
    "model_bert_fntune_wtattn_2emb = build_model_bert(MAX_SEQ_LEN, True, True, True)\n",
    "\n",
    "initialize_vars(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elmo_fntune_wtattn_1emb.load_weights('./model_weights/finetune/elmo/1emb/model_elmo_notarg_wtattn_bws_cvTwrd0.h5')\n",
    "model_elmo_fntune_wtattn_2emb.load_weights('./model_weights/finetune/elmo/2emb/model_elmo_notarg_wtattn_bws_cvTwrd0.h5')\n",
    "model_bert_fntune_wtattn_1emb.load_weights('./model_weights/finetune/bert/1emb/model_bert_notarg_wtattn_lrlow_bws_cvTwrd0.h5')\n",
    "model_bert_fntune_wtattn_2emb.load_weights('./model_weights/finetune/bert/2emb/model_bert_notarg_wtattn_lrlow_bws_cvTwrd0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_elmo_fntune_attn_1emb = Model(model_elmo_fntune_wtattn_1emb.inputs, model_elmo_fntune_wtattn_1emb.get_layer(\"attention_layer\").output[1])\n",
    "model_elmo_fntune_attn_2emb = Model(model_elmo_fntune_wtattn_2emb.inputs, model_elmo_fntune_wtattn_2emb.get_layer(\"attention_layer\").output[1])\n",
    "model_bert_fntune_attn_1emb = Model(model_bert_fntune_wtattn_1emb.inputs, model_bert_fntune_wtattn_1emb.get_layer(\"attention_layer\").output[1])\n",
    "model_bert_fntune_attn_2emb = Model(model_bert_fntune_wtattn_2emb.inputs, model_bert_fntune_wtattn_2emb.get_layer(\"attention_layer\").output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_fntune_attn_pred_1emb = model_elmo_fntune_attn_1emb.predict(sentences_notarg)[:,0,:]\n",
    "elmo_fntune_attn_pred_2emb = model_elmo_fntune_attn_2emb.predict(sentences_wttarg)[:,0,:]\n",
    "bert_fntune_attn_pred_1emb = model_bert_fntune_attn_1emb.predict(sentences_bert_input)[:,0,:]\n",
    "bert_fntune_attn_pred_2emb = model_bert_fntune_attn_2emb.predict(sentences_bert_input)[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.00587391, 0.00722504, 0.01977579, 0.00249211,\n",
       "       0.04735354, 0.02717614, 0.08150709, 0.00613867, 0.05270234,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_fntune_attn_pred_2emb[7] * sentences_notarg[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.01575179, 0.01531768, 0.0157336 , 0.01595803,\n",
       "       0.01511277, 0.01564112, 0.01736445, 0.01687797, 0.0189434 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_fntune_attn_pred_2emb[7] * sentences_notarg[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.02253668, 0.01665933, 0.02678995, 0.02176848,\n",
       "       0.02169131, 0.02165814, 0.02651314, 0.02223309, 0.0330233 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elmo_fntune_attn_pred_1emb[7] * sentences_notarg[2][7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'bert_finetune_2emb')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2016x720 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2, 2, figsize=(28, 10))\n",
    "\n",
    "axes[0][0].bar(x=sentences_notarg[1][7], height=min_max_sc(elmo_fntune_attn_pred_1emb[7] * sentences_notarg[2][7]))\n",
    "axes[0][1].bar(x=sentences_notarg[1][7], height=min_max_sc(elmo_fntune_attn_pred_2emb[7] * sentences_notarg[2][7]))\n",
    "axes[1][0].bar(x=sentences_notarg[1][7], height=min_max_sc(bert_fntune_attn_pred_1emb[7] * sentences_notarg[2][7]))\n",
    "axes[1][1].bar(x=sentences_notarg[1][7], height=min_max_sc(bert_fntune_attn_pred_2emb[7] * sentences_notarg[2][7]))\n",
    "\n",
    "axes[0][0].set_title(\"elmo_finetune_1emb\")\n",
    "axes[0][1].set_title(\"elmo_finetune_2emb\")\n",
    "axes[1][0].set_title(\"bert_finetune_1emb\")\n",
    "axes[1][1].set_title(\"bert_finetune_2emb\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_pair_loc: 9 relation_cue_loc: 6\n"
     ]
    }
   ],
   "source": [
    "print(\"target_pair_loc:\", np.where(sentences_notarg[4][7])[0][0], \n",
    "      \"relation_cue_loc:\", np.where(sentences_notarg[5][7])[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0]),\n",
       " array([7, 2]),\n",
       " array([1]),\n",
       " array([3, 0]),\n",
       " array([1]),\n",
       " array([4, 0]),\n",
       " array([0]),\n",
       " array([6, 1])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[attention_ranks(elmo_fntune_attn_pred_1emb[7], sentences_notarg[2][7], sentences_notarg[4][7]), attention_ranks(elmo_fntune_attn_pred_1emb[7], sentences_notarg[2][7], sentences_notarg[5][7]),\n",
    " attention_ranks(elmo_fntune_attn_pred_2emb[7], sentences_notarg[2][7], sentences_notarg[4][7]), attention_ranks(elmo_fntune_attn_pred_2emb[7], sentences_notarg[2][7], sentences_notarg[5][7]),\n",
    " attention_ranks(bert_fntune_attn_pred_1emb[7], sentences_notarg[2][7], sentences_notarg[4][7]), attention_ranks(bert_fntune_attn_pred_1emb[7], sentences_notarg[2][7], sentences_notarg[5][7]),\n",
    " attention_ranks(bert_fntune_attn_pred_2emb[7], sentences_notarg[2][7], sentences_notarg[4][7]), attention_ranks(bert_fntune_attn_pred_2emb[7], sentences_notarg[2][7], sentences_notarg[5][7]),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1.  , 0.55]),\n",
       " array([0.9 , 0.85]),\n",
       " array([0.9, 0.8]),\n",
       " array([1.  , 0.65])]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[attention_scores(elmo_fntune_attn_pred_1emb[7], sentences_notarg[0][7], sentences_notarg[2][7], sentences_notarg[4][7], sentences_notarg[5][7]),\n",
    " attention_scores(elmo_fntune_attn_pred_2emb[7], sentences_notarg[0][7], sentences_notarg[2][7], sentences_notarg[4][7], sentences_notarg[5][7]),\n",
    " attention_scores(bert_fntune_attn_pred_1emb[7], sentences_notarg[0][7], sentences_notarg[2][7], sentences_notarg[4][7], sentences_notarg[5][7]),\n",
    " attention_scores(bert_fntune_attn_pred_2emb[7], sentences_notarg[0][7], sentences_notarg[2][7], sentences_notarg[4][7], sentences_notarg[5][7])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_fntune_1emb_attscore = np.array([attention_scores(elmo_fntune_attn_pred_1emb[i], sentences_notarg[0][i], sentences_notarg[2][i], sentences_notarg[4][i], sentences_notarg[5][i]) for i in range(df_eval.shape[0])])\n",
    "elmo_fntune_2emb_attscore = np.array([attention_scores(elmo_fntune_attn_pred_2emb[i], sentences_notarg[0][i], sentences_notarg[2][i], sentences_notarg[4][i], sentences_notarg[5][i]) for i in range(df_eval.shape[0])])\n",
    "bert_fntune_1emb_attscore = np.array([attention_scores(bert_fntune_attn_pred_1emb[i], sentences_notarg[0][i], sentences_notarg[2][i], sentences_notarg[4][i], sentences_notarg[5][i]) for i in range(df_eval.shape[0])])\n",
    "bert_fntune_2emb_attscore = np.array([attention_scores(bert_fntune_attn_pred_2emb[i], sentences_notarg[0][i], sentences_notarg[2][i], sentences_notarg[4][i], sentences_notarg[5][i]) for i in range(df_eval.shape[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval['elmo_fntune_1emb_attscore_pair'] = elmo_fntune_1emb_attscore[:,0]\n",
    "df_eval['elmo_fntune_1emb_attscore_rcue'] = elmo_fntune_1emb_attscore[:,1]\n",
    "df_eval['elmo_fntune_2emb_attscore_pair'] = elmo_fntune_2emb_attscore[:,0]\n",
    "df_eval['elmo_fntune_2emb_attscore_rcue'] = elmo_fntune_2emb_attscore[:,1]\n",
    "df_eval['bert_fntune_1emb_attscore_pair'] = bert_fntune_1emb_attscore[:,0]\n",
    "df_eval['bert_fntune_1emb_attscore_rcue'] = bert_fntune_1emb_attscore[:,1]\n",
    "df_eval['bert_fntune_2emb_attscore_pair'] = bert_fntune_2emb_attscore[:,0]\n",
    "df_eval['bert_fntune_2emb_attscore_rcue'] = bert_fntune_2emb_attscore[:,1]\n",
    "df_eval['elmo_fntune_1emb_attscore_sum'] = df_eval['elmo_fntune_1emb_attscore_pair']+df_eval['elmo_fntune_1emb_attscore_rcue']\n",
    "df_eval['elmo_fntune_2emb_attscore_sum'] = df_eval['elmo_fntune_2emb_attscore_pair']+df_eval['elmo_fntune_2emb_attscore_rcue']\n",
    "df_eval['bert_fntune_1emb_attscore_sum'] = df_eval['bert_fntune_1emb_attscore_pair']+df_eval['bert_fntune_1emb_attscore_rcue']\n",
    "df_eval['bert_fntune_2emb_attscore_sum'] = df_eval['bert_fntune_2emb_attscore_pair']+df_eval['bert_fntune_2emb_attscore_rcue']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Score: pair < rcue\n",
    "    - if context does not include the target word\n",
    "        - Antonym, HasProperty, Synonym\n",
    "    - if context does include the target word\n",
    "        - Entails, MadeOf\n",
    "- Score: no target < with target\n",
    "    - target-pair word\n",
    "        - IsA\n",
    "    - relational cue\n",
    "        - MadeOf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>elmo_fntune_1emb_attscore_pair</th>\n",
       "      <th>elmo_fntune_1emb_attscore_rcue</th>\n",
       "      <th>elmo_fntune_1emb_attscore_sum</th>\n",
       "      <th>elmo_fntune_2emb_attscore_pair</th>\n",
       "      <th>elmo_fntune_2emb_attscore_rcue</th>\n",
       "      <th>elmo_fntune_2emb_attscore_sum</th>\n",
       "      <th>bert_fntune_1emb_attscore_pair</th>\n",
       "      <th>bert_fntune_1emb_attscore_rcue</th>\n",
       "      <th>bert_fntune_1emb_attscore_sum</th>\n",
       "      <th>bert_fntune_2emb_attscore_pair</th>\n",
       "      <th>bert_fntune_2emb_attscore_rcue</th>\n",
       "      <th>bert_fntune_2emb_attscore_sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relation</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Antonym</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.874</td>\n",
       "      <td>1.813</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.820</td>\n",
       "      <td>0.909</td>\n",
       "      <td>0.857</td>\n",
       "      <td>1.766</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.791</td>\n",
       "      <td>1.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Entails</th>\n",
       "      <td>0.850</td>\n",
       "      <td>0.669</td>\n",
       "      <td>1.519</td>\n",
       "      <td>0.873</td>\n",
       "      <td>0.625</td>\n",
       "      <td>1.498</td>\n",
       "      <td>0.747</td>\n",
       "      <td>0.641</td>\n",
       "      <td>1.388</td>\n",
       "      <td>0.771</td>\n",
       "      <td>0.554</td>\n",
       "      <td>1.325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasA</th>\n",
       "      <td>0.940</td>\n",
       "      <td>0.675</td>\n",
       "      <td>1.615</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.453</td>\n",
       "      <td>1.453</td>\n",
       "      <td>0.972</td>\n",
       "      <td>0.589</td>\n",
       "      <td>1.561</td>\n",
       "      <td>0.963</td>\n",
       "      <td>0.787</td>\n",
       "      <td>1.749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HasProperty</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.889</td>\n",
       "      <td>1.828</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.856</td>\n",
       "      <td>1.831</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.723</td>\n",
       "      <td>1.651</td>\n",
       "      <td>0.996</td>\n",
       "      <td>0.736</td>\n",
       "      <td>1.732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsA</th>\n",
       "      <td>0.939</td>\n",
       "      <td>0.334</td>\n",
       "      <td>1.273</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.338</td>\n",
       "      <td>1.295</td>\n",
       "      <td>0.945</td>\n",
       "      <td>0.856</td>\n",
       "      <td>1.801</td>\n",
       "      <td>0.980</td>\n",
       "      <td>0.809</td>\n",
       "      <td>1.788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MadeOf</th>\n",
       "      <td>0.968</td>\n",
       "      <td>0.821</td>\n",
       "      <td>1.789</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.810</td>\n",
       "      <td>1.792</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.636</td>\n",
       "      <td>1.501</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.412</td>\n",
       "      <td>1.295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MemberOf</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.427</td>\n",
       "      <td>1.427</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.760</td>\n",
       "      <td>1.760</td>\n",
       "      <td>0.984</td>\n",
       "      <td>0.771</td>\n",
       "      <td>1.755</td>\n",
       "      <td>0.937</td>\n",
       "      <td>0.682</td>\n",
       "      <td>1.620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PartOf</th>\n",
       "      <td>0.985</td>\n",
       "      <td>0.395</td>\n",
       "      <td>1.380</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.733</td>\n",
       "      <td>1.720</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.814</td>\n",
       "      <td>1.634</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.472</td>\n",
       "      <td>1.360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Synonym</th>\n",
       "      <td>0.865</td>\n",
       "      <td>0.600</td>\n",
       "      <td>1.465</td>\n",
       "      <td>0.789</td>\n",
       "      <td>0.836</td>\n",
       "      <td>1.624</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.752</td>\n",
       "      <td>1.640</td>\n",
       "      <td>0.965</td>\n",
       "      <td>0.695</td>\n",
       "      <td>1.660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>overall avg.</th>\n",
       "      <td>0.933</td>\n",
       "      <td>0.639</td>\n",
       "      <td>1.572</td>\n",
       "      <td>0.925</td>\n",
       "      <td>0.696</td>\n",
       "      <td>1.622</td>\n",
       "      <td>0.912</td>\n",
       "      <td>0.783</td>\n",
       "      <td>1.695</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.725</td>\n",
       "      <td>1.691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              elmo_fntune_1emb_attscore_pair  elmo_fntune_1emb_attscore_rcue  \\\n",
       "relation                                                                       \n",
       "Antonym       0.939                           0.874                            \n",
       "Entails       0.850                           0.669                            \n",
       "HasA          0.940                           0.675                            \n",
       "HasProperty   0.939                           0.889                            \n",
       "IsA           0.939                           0.334                            \n",
       "MadeOf        0.968                           0.821                            \n",
       "MemberOf      1.000                           0.427                            \n",
       "PartOf        0.985                           0.395                            \n",
       "Synonym       0.865                           0.600                            \n",
       "overall avg.  0.933                           0.639                            \n",
       "\n",
       "              elmo_fntune_1emb_attscore_sum  elmo_fntune_2emb_attscore_pair  \\\n",
       "relation                                                                      \n",
       "Antonym       1.813                          0.878                            \n",
       "Entails       1.519                          0.873                            \n",
       "HasA          1.615                          1.000                            \n",
       "HasProperty   1.828                          0.975                            \n",
       "IsA           1.273                          0.957                            \n",
       "MadeOf        1.789                          0.982                            \n",
       "MemberOf      1.427                          1.000                            \n",
       "PartOf        1.380                          0.988                            \n",
       "Synonym       1.465                          0.789                            \n",
       "overall avg.  1.572                          0.925                            \n",
       "\n",
       "              elmo_fntune_2emb_attscore_rcue  elmo_fntune_2emb_attscore_sum  \\\n",
       "relation                                                                      \n",
       "Antonym       0.942                           1.820                           \n",
       "Entails       0.625                           1.498                           \n",
       "HasA          0.453                           1.453                           \n",
       "HasProperty   0.856                           1.831                           \n",
       "IsA           0.338                           1.295                           \n",
       "MadeOf        0.810                           1.792                           \n",
       "MemberOf      0.760                           1.760                           \n",
       "PartOf        0.733                           1.720                           \n",
       "Synonym       0.836                           1.624                           \n",
       "overall avg.  0.696                           1.622                           \n",
       "\n",
       "              bert_fntune_1emb_attscore_pair  bert_fntune_1emb_attscore_rcue  \\\n",
       "relation                                                                       \n",
       "Antonym       0.909                           0.857                            \n",
       "Entails       0.747                           0.641                            \n",
       "HasA          0.972                           0.589                            \n",
       "HasProperty   0.927                           0.723                            \n",
       "IsA           0.945                           0.856                            \n",
       "MadeOf        0.865                           0.636                            \n",
       "MemberOf      0.984                           0.771                            \n",
       "PartOf        0.820                           0.814                            \n",
       "Synonym       0.888                           0.752                            \n",
       "overall avg.  0.912                           0.783                            \n",
       "\n",
       "              bert_fntune_1emb_attscore_sum  bert_fntune_2emb_attscore_pair  \\\n",
       "relation                                                                      \n",
       "Antonym       1.766                          0.986                            \n",
       "Entails       1.388                          0.771                            \n",
       "HasA          1.561                          0.963                            \n",
       "HasProperty   1.651                          0.996                            \n",
       "IsA           1.801                          0.980                            \n",
       "MadeOf        1.501                          0.883                            \n",
       "MemberOf      1.755                          0.937                            \n",
       "PartOf        1.634                          0.888                            \n",
       "Synonym       1.640                          0.965                            \n",
       "overall avg.  1.695                          0.966                            \n",
       "\n",
       "              bert_fntune_2emb_attscore_rcue  bert_fntune_2emb_attscore_sum  \n",
       "relation                                                                     \n",
       "Antonym       0.791                           1.776                          \n",
       "Entails       0.554                           1.325                          \n",
       "HasA          0.787                           1.749                          \n",
       "HasProperty   0.736                           1.732                          \n",
       "IsA           0.809                           1.788                          \n",
       "MadeOf        0.412                           1.295                          \n",
       "MemberOf      0.682                           1.620                          \n",
       "PartOf        0.472                           1.360                          \n",
       "Synonym       0.695                           1.660                          \n",
       "overall avg.  0.725                           1.691                          "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = df_eval.groupby('relation').apply(lambda df:df[['elmo_fntune_1emb_attscore_pair', 'elmo_fntune_1emb_attscore_rcue', 'elmo_fntune_1emb_attscore_sum',\n",
    "                                                     'elmo_fntune_2emb_attscore_pair', 'elmo_fntune_2emb_attscore_rcue', 'elmo_fntune_2emb_attscore_sum',\n",
    "                                                     'bert_fntune_1emb_attscore_pair', 'bert_fntune_1emb_attscore_rcue', 'bert_fntune_1emb_attscore_sum',\n",
    "                                                     'bert_fntune_2emb_attscore_pair', 'bert_fntune_2emb_attscore_rcue', 'bert_fntune_2emb_attscore_sum']].mean())\n",
    "# tt.loc['sum'] = tt.sum(axis=0)\n",
    "tt.loc['overall avg.'] = [df_eval['elmo_fntune_1emb_attscore_pair'].mean(), df_eval['elmo_fntune_1emb_attscore_rcue'].mean(), df_eval['elmo_fntune_1emb_attscore_sum'].mean(),\n",
    "                          df_eval['elmo_fntune_2emb_attscore_pair'].mean(), df_eval['elmo_fntune_2emb_attscore_rcue'].mean(), df_eval['elmo_fntune_2emb_attscore_sum'].mean(),\n",
    "                          df_eval['bert_fntune_1emb_attscore_pair'].mean(), df_eval['bert_fntune_1emb_attscore_rcue'].mean(), df_eval['bert_fntune_1emb_attscore_sum'].mean(),\n",
    "                          df_eval['bert_fntune_2emb_attscore_pair'].mean(), df_eval['bert_fntune_2emb_attscore_rcue'].mean(), df_eval['bert_fntune_2emb_attscore_sum'].mean(),]\n",
    "tt.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Santus et al., 2015: The list of relationship and example relational cues\n",
    "<img src=\"dataset/EVALution_1.0/santus_et_al__hearst.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pair': (0.932894489010179,\n",
       "  0.9250598694563924,\n",
       "  Ttest_indResult(statistic=3.0323790590719595, pvalue=0.002430492159064255)),\n",
       " 'rcue': (0.6386956572821495,\n",
       "  0.6964591058424481,\n",
       "  Ttest_indResult(statistic=-14.226127392194943, pvalue=1.2501849485749334e-45)),\n",
       " 'sum': (1.5715901462923285,\n",
       "  1.6215189752988406,\n",
       "  Ttest_indResult(statistic=-11.137070025545887, pvalue=1.0732130620320087e-28))}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# elmo finetune: 1emb vs 2emb\n",
    "{\"pair\":(df_eval['elmo_fntune_1emb_attscore_pair'].mean(), df_eval['elmo_fntune_2emb_attscore_pair'].mean(), ttest_ind(df_eval['elmo_fntune_1emb_attscore_pair'], df_eval['elmo_fntune_2emb_attscore_pair'])),\n",
    " \"rcue\":(df_eval['elmo_fntune_1emb_attscore_rcue'].mean(), df_eval['elmo_fntune_2emb_attscore_rcue'].mean(), ttest_ind(df_eval['elmo_fntune_1emb_attscore_rcue'], df_eval['elmo_fntune_2emb_attscore_rcue'])),\n",
    " \"sum\": (df_eval['elmo_fntune_1emb_attscore_sum'].mean(),   df_eval['elmo_fntune_2emb_attscore_sum'].mean(),  ttest_ind(df_eval['elmo_fntune_1emb_attscore_sum'], df_eval['elmo_fntune_2emb_attscore_sum']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pair': (0.911693378821649,\n",
       "  0.9658981224192449,\n",
       "  Ttest_indResult(statistic=-21.825092421905037, pvalue=5.550848372764604e-104)),\n",
       " 'rcue': (0.7830985430474886,\n",
       "  0.7247125842360761,\n",
       "  Ttest_indResult(statistic=24.122770820107824, pvalue=3.626560267898265e-126)),\n",
       " 'sum': (1.6947919218691376,\n",
       "  1.6906107066553209,\n",
       "  Ttest_indResult(statistic=1.2477970390007243, pvalue=0.21212489532194265))}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bert finetune: 1emb vs 2emb\n",
    "{\"pair\":(df_eval['bert_fntune_1emb_attscore_pair'].mean(), df_eval['bert_fntune_2emb_attscore_pair'].mean(), ttest_ind(df_eval['bert_fntune_1emb_attscore_pair'], df_eval['bert_fntune_2emb_attscore_pair'])),\n",
    " \"rcue\":(df_eval['bert_fntune_1emb_attscore_rcue'].mean(), df_eval['bert_fntune_2emb_attscore_rcue'].mean(), ttest_ind(df_eval['bert_fntune_1emb_attscore_rcue'], df_eval['bert_fntune_2emb_attscore_rcue'])),\n",
    " \"sum\": (df_eval['bert_fntune_1emb_attscore_sum'].mean(),  df_eval['bert_fntune_2emb_attscore_sum'].mean(),  ttest_ind(df_eval['bert_fntune_1emb_attscore_sum'],  df_eval['bert_fntune_2emb_attscore_sum']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pair': (0.932894489010179,\n",
       "  0.911693378821649,\n",
       "  Ttest_indResult(statistic=7.897790538860468, pvalue=3.035038608037792e-15)),\n",
       " 'rcue': (0.6386956572821495,\n",
       "  0.7830985430474886,\n",
       "  Ttest_indResult(statistic=-44.082691149252966, pvalue=0.0)),\n",
       " 'sum': (1.5715901462923285,\n",
       "  1.6947919218691376,\n",
       "  Ttest_indResult(statistic=-31.287042410112456, pvalue=3.270802093883017e-208))}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1emb finetune: elmo vs bert\n",
    "{\"pair\":(df_eval['elmo_fntune_1emb_attscore_pair'].mean(), df_eval['bert_fntune_1emb_attscore_pair'].mean(), ttest_ind(df_eval['elmo_fntune_1emb_attscore_pair'], df_eval['bert_fntune_1emb_attscore_pair'])),\n",
    " \"rcue\":(df_eval['elmo_fntune_1emb_attscore_rcue'].mean(), df_eval['bert_fntune_1emb_attscore_rcue'].mean(), ttest_ind(df_eval['elmo_fntune_1emb_attscore_rcue'], df_eval['bert_fntune_1emb_attscore_rcue'])),\n",
    " \"sum\" :(df_eval['elmo_fntune_1emb_attscore_sum'].mean(),  df_eval['bert_fntune_1emb_attscore_sum'].mean(),  ttest_ind(df_eval['elmo_fntune_1emb_attscore_sum'],  df_eval['bert_fntune_1emb_attscore_sum']))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pair': (0.9250598694563924,\n",
       "  0.9658981224192449,\n",
       "  Ttest_indResult(statistic=-17.20007559423212, pvalue=1.1319652188054198e-65)),\n",
       " 'rcue': (0.6964591058424481,\n",
       "  0.7247125842360761,\n",
       "  Ttest_indResult(statistic=-8.290344355385239, pvalue=1.2243089490784005e-16)),\n",
       " 'sum': (1.6215189752988406,\n",
       "  1.6906107066553209,\n",
       "  Ttest_indResult(statistic=-17.370608321793817, pvalue=6.23038793636646e-67))}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2emb finetune: elmo vs bert\n",
    "{\"pair\":(df_eval['elmo_fntune_2emb_attscore_pair'].mean(), df_eval['bert_fntune_2emb_attscore_pair'].mean(), ttest_ind(df_eval['elmo_fntune_2emb_attscore_pair'], df_eval['bert_fntune_2emb_attscore_pair'])),\n",
    " \"rcue\":(df_eval['elmo_fntune_2emb_attscore_rcue'].mean(), df_eval['bert_fntune_2emb_attscore_rcue'].mean(), ttest_ind(df_eval['elmo_fntune_2emb_attscore_rcue'], df_eval['bert_fntune_2emb_attscore_rcue'])),\n",
    " \"sum\" :(df_eval['elmo_fntune_2emb_attscore_sum'].mean(),  df_eval['bert_fntune_2emb_attscore_sum'].mean(),  ttest_ind(df_eval['elmo_fntune_2emb_attscore_sum'],  df_eval['bert_fntune_2emb_attscore_sum']))}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
